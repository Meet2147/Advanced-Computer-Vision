{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"EEGAnalysis.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Iy6b3On-qBEc","colab_type":"text"},"source":["## Event Classification from EEG\n","#### Tyrome Sweet and Taran Rallings"]},{"cell_type":"markdown","metadata":{"id":"_clz82B7qBEh","colab_type":"text"},"source":["### Introduction\n"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"E_xpmblzqBEi","colab_type":"text"},"source":["The following analyes EEG data taken in experiments where participants where exposed to light and sound events. This code cleans that 32 channel EEG data and uses a long short-term memory recurrent neural network to classify the time following light or sound events by which event occured. "]},{"cell_type":"markdown","metadata":{"id":"qgxkEDrEqBEj","colab_type":"text"},"source":["### Data Prep\n","\n"]},{"cell_type":"code","metadata":{"id":"82iheqV3qBEk","colab_type":"code","colab":{}},"source":["#! git clone https://github.com/Cerebro409/EEG-Classification-Using-Recurrent-Neural-Network.git\n","# setting the random seed for reproducibility\n","import random\n","seed=42\n","random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7wYd-WW5dae","colab_type":"code","outputId":"7b16f6fa-97f2-4ec8-f5e5-56a004628a3a","executionInfo":{"status":"error","timestamp":1573562927729,"user_tz":-330,"elapsed":59935,"user":{"displayName":"AVARI FARZAD","photoUrl":"","userId":"06062050648998271274"}},"colab":{"base_uri":"https://localhost:8080/","height":557}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"1iGiUroOq0sz","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"wMCEHMlVqBEo","colab_type":"code","colab":{}},"source":["# import libraries \n","import itertools\n","import numpy as np\n","import pandas as pd\n","from sklearn import preprocessing\n","from sklearn.preprocessing import StandardScaler"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nmemOfAUqBEr","colab_type":"text"},"source":["### Load the Data"]},{"cell_type":"code","metadata":{"id":"j36cUJJpqBEs","colab_type":"code","colab":{}},"source":["# eeg1 and events1 are the test data from a single person\n","# code assumes eeg1 and events1 are csv files in the current working directory\n","\n","eeg1 = pd.read_csv(\"/content/drive/My Drive/BCAI/Dataset/eeg1.csv\", delimiter=\"\\t\")\n","new_columns = eeg1.columns.values \n","new_columns[0] = 'time'     \n","new_columns[33] = 'sample' \n","eeg1.columns = new_columns\n","\n","events1 = pd.read_csv(\"/content/drive/My Drive/BCAI/Dataset/events1.csv\") #, delimiter=\"\\t\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ovJgiCywqBEu","colab_type":"code","colab":{}},"source":["# subsample of the data to ease building the model, unused in final run\n","eeg1_smol = eeg1[0:785000]\n","events1_smol = events1[0:1000]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dcD8jj7qBEx","colab_type":"code","colab":{}},"source":["# Toy data generator, unused in final run\n","\n","def generate_eeg(samples, time_steps, n_features, event_types):\n","    # samples is Int number of trials \n","    # time_steps is Int length of each trial in ms\n","    # n_features is Int number of EEG channels\n","    # event_types is Int number of stimula like lights and flashes\n","    signals = generate_signals(samples, time_steps, n_features)\n","    events = generate_events(event_types, samples)\n","    events_1hot = one_hot_events(events)\n","    return signals, events_1hot\n","\n","# helper function (generate_eeg) for making EEG signal data\n","def generate_signals(samples, time_steps, n_features):\n","    # data types same as main function\n","    signals = np.random.random((samples, time_steps, n_features))\n","    return signals\n","\n","# helper function (generate_eeg) for making one sample per event an\n","def generate_events(event_types, samples):\n","    # data types same as main function\n","    events = np.random.randint(1, event_types, samples)\n","    return events"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aiEaqjmsqBE0","colab_type":"code","colab":{}},"source":["# takes in eeg dataframe and event dataframe, cleans them, 1hot encodes the events\n","def clean_eeg(eeg, events, event_interval_length, eeg_slice_length):\n","    #event_list = []\n","    array_list = [] \n","    index_list = []\n","    eeg = standardize_eeg(eeg) # function for standardizing the eeg readings\n","    #events_new = build_zero_events(events)\n","    # iterate over the rows of the events and slice out the corresponding eeg data\n","    for index, row in itertools.islice(events.iterrows(), event_interval_length): # loop through events data\n","        #build_event_list(row, event_list) #\n","        tmin, tmax = build_event_intervals(row, events)\n","        eeg_slice = cut_event_intervals(eeg, tmin, tmax)\n","        array_list, index_list = build_array(eeg_slice, eeg_slice_length, \n","                                             index, index_list, array_list)\n","    y_int = events.iloc[index_list] # take the event types for the correct index\n","    y_int = y_int['type'].values    # take just the event types as an array\n","    #y_int = y_int.as_matrix()            # save the event types as a matrix\n","    #y, lb = one_hot_events(y_int)        # one-hot the event types and save the binarizer\n","    X = np.stack(array_list, axis = 0)   # stack the arrays so the whole thing is 3D\n","    return X, y_int                     # return the data, outputs, and the binarizer\n","    \n","        \n","def build_event_list(row, event_list):\n","    # helper function to pull event types out of event data in the right order\n","    event_type = getattr(row, \"type\")\n","    event_list.append(event_type)\n","        \n","def build_event_intervals(row, events):\n","    # helper function to get the time intervals associated with each event\n","    tmin = getattr(row, \"latency\")\n","    tmin_in = getattr(row, \"number\")\n","    tmax_in = tmin_in + 1\n","    tmax = events1.loc[tmax_in, \"latency\"]\n","    return tmin, tmax\n","\n","def cut_event_intervals(eeg, tmin, tmax):\n","    # helper function to slice up the eeg data so each slice is associated with one event\n","    eeg_slice = eeg.loc[(eeg[\"time\"] > tmin) & (eeg[\"time\"] < tmax)]\n","    eeg_slice.drop([\"time\", \"sample\"], axis = 1, inplace = True)\n","    return eeg_slice\n","    \n","def build_array(eeg_slice, eeg_slice_length, index, index_list, array_list):\n","    # helper function to build an array out of the eeg slices and pad them out to a standard length\n","    if len(eeg_slice) < eeg_slice_length:\n","        index_list.append(index)\n","        eeg_matrix = eeg_slice.as_matrix()\n","        padded_matrix = np.pad(eeg_matrix, ((0, eeg_slice_length - len(eeg_matrix)), (0,0)),\n","                                   'constant', constant_values=0)\n","        array_list.append(padded_matrix)\n","    return array_list, index_list\n","\n","def one_hot_events(events):\n","    # helper function for one-hot encoding the events\n","    events_list = list(events)\n","    lb = preprocessing.LabelBinarizer()\n","    lb.fit(events_list)\n","    events_1hot = lb.transform(events_list)\n","    return events_1hot, lb\n","\n","def invert_one_hot(events, lb):\n","    # function for decoding one-hot, binarizer made in one_hot_events\n","    inv_events = lb.inverse_transform(events)\n","    return inv_events"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QjiP11P9qBE2","colab_type":"code","colab":{}},"source":["def standardize_eeg(eeg_data):\n","    # breaks apart an eeg dataframe, scales the eeg readings, and reassmbles it into a dataframe\n","    column_list = eeg_data.columns[1:33]\n","    time = eeg_data['time']\n","    sample = eeg_data['sample']\n","    eeg_array = eeg_data[column_list]\n","    eeg_stnd = scale_data(eeg_array)\n","    eeg_stnd_df = pd.DataFrame(eeg_stnd, index=eeg_data.index, columns=column_list)\n","    eeg_stnd = pd.concat([time, eeg_stnd_df, sample], axis =1)\n","    return eeg_stnd\n","\n","def scale_data(unscaled_data):\n","    # helper function for standardize_eeg, fits a scaler and transforms the data \n","    scaler = StandardScaler()\n","    scaler.fit(unscaled_data)\n","    scaled_data = scaler.transform(unscaled_data)\n","    return scaled_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5SHrb1u3qBE5","colab_type":"code","colab":{}},"source":["# This is unused code for breaking up the \"nothing happened\" periods of the eeg data \n","# to associate with \"type 0\" events. \n","\n","import math\n","time_steps = 1300\n","\n","def build_zero_events(event_data, time_steps=time_steps):\n","    new_events = build_new_events(event_data, time_steps)\n","    events = zero_events(event_data, new_events)\n","    return events\n","\n","\n","def build_new_events(event_data, time_steps= time_steps):\n","    first_event_time = event_data['latency'].loc[1]\n","    number_new_intervals = math.floor(first_event_time / time_steps)\n","    df = pd.DataFrame(columns=['number', 'latency', 'type', 'duration'],index = range(number_new_intervals) )\n","    latency = 0\n","    for t in range(number_new_intervals):\n","        latency += 1300\n","        df.loc[t].latency = latency\n","        df.loc[t].type = 0\n","    return df\n","\n","def zero_events(event_data, new_events):\n","    events_zeros = event_data[event_data.latency != 1]\n","    events_zeros= new_events.append(events_zeros)\n","    events_zeros = events_zeros.reset_index(drop=True)\n","    events_zeros['number'] = events_zeros.index + 1\n","    return events_zeros"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v8ZbhL9bqBE7","colab_type":"text"},"source":["### Model\n","\n"]},{"cell_type":"code","metadata":{"id":"d3E_9kexqBE8","colab_type":"code","colab":{}},"source":["# full dataset parameters\n","\n","# define model parameters\n","samples = 3625  # how many trials of eeg data\n","n_features = 32  # how many channels of eeg in each sample\n","time_steps = 1300 # how many ms was each sample run for\n","event_types = 2 #len(set(y))  # how many different event types (light, sound, etc) are there # 6 large, 4 smol"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T7GKWDhSqBFA","colab_type":"code","outputId":"da821116-911e-4fb5-b367-843e72630450","executionInfo":{"status":"ok","timestamp":1573198654534,"user_tz":-330,"elapsed":58839,"user":{"displayName":"AVARI FARZAD","photoUrl":"","userId":"06062050648998271274"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["# get the data into useable form and store as X and y\n","X, y = clean_eeg(eeg1, events1, samples, time_steps)  #4250 long, 998 short, 4330 long enhanced"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dNFFqSQKqBFG","colab_type":"code","colab":{}},"source":["# removes the minor event types. There were only a couple hundred examples of each, whereas the used events had a \n","# couple thousand examples\n","remove_list = [0,2,4,5,6]              # designate unwanted event types\n","drop_list = np.isin(y, remove_list)    # create a list of indices associated with unwanted events                  \n","drop_array = np.array(drop_list)       # make the list of indices to drop into an array"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wbaC4SyqBFI","colab_type":"code","colab":{}},"source":["# make X, y's with the unwanted events removed\n","y_short_int = y[np.isin(y,remove_list, invert=True)]\n","X_short = X[np.isin(y, remove_list, invert=True)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"epJ6ZB0dqBFM","colab_type":"code","colab":{}},"source":["# one hot encode the y data without the unwanted events\n","y_short, lb = one_hot_events(y_short_int) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxbZJGO-qBFQ","colab_type":"code","outputId":"17f920e0-a116-4c17-9941-6cbf9314aa19","executionInfo":{"status":"ok","timestamp":1573198682981,"user_tz":-330,"elapsed":1405,"user":{"displayName":"AVARI FARZAD","photoUrl":"","userId":"06062050648998271274"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from sklearn.model_selection import StratifiedShuffleSplit\n","\n","# use strat. shuffle split to get indices for test and training data \n","sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=seed)\n","sss.get_n_splits(X_short, y_short)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"sFgvJSMDqBFS","colab_type":"code","colab":{}},"source":["# take the indices generated by stratified shuffle split and make the test and training datasets\n","for train_index, test_index in sss.split(X_short, y_short):\n","    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","    X_train, X_test = X_short[train_index], X_short[test_index]\n","    y_train, y_test = y_short[train_index], y_short[test_index]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbkHF_2FyRwk","colab_type":"code","outputId":"bcec9289-99b6-4245-97da-3a03396e22ca","executionInfo":{"status":"ok","timestamp":1573198713355,"user_tz":-330,"elapsed":6178,"user":{"displayName":"AVARI FARZAD","photoUrl":"","userId":"06062050648998271274"}},"colab":{"base_uri":"https://localhost:8080/","height":99}},"source":["!pip install tensorboardcolab\n","import tensorflow as tf\n","%load_ext tensorboard"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"gW5H_NSG8ZFO","colab_type":"code","outputId":"4155d67f-f154-4341-c5a6-eef291a1bb17","executionInfo":{"status":"ok","timestamp":1573198732762,"user_tz":-330,"elapsed":17950,"user":{"displayName":"AVARI FARZAD","photoUrl":"","userId":"06062050648998271274"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["from tensorboardcolab import *\n","tbc=TensorBoardColab()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","https://b376f601.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iYxWauwOqBFV","colab_type":"code","outputId":"fd8992f7-8c48-4d41-94f4-0ed0c5cd47ca","executionInfo":{"status":"ok","timestamp":1573204913574,"user_tz":-330,"elapsed":6175381,"user":{"displayName":"AVARI FARZAD","photoUrl":"","userId":"06062050648998271274"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.layers import Embedding\n","from keras.layers import LSTM\n","\n","\n","# code for building an LSTM with 100 neurons and dropout. Runs for 50 epochs\n","\n","model = Sequential()\n","model.add(LSTM(100, return_sequences=False, input_shape=(time_steps, n_features)))\n","model.add(Dropout(0.5))\n","#model.add(LSTM(100)) dramatically worse results\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, batch_size=16, epochs=25,callbacks=[TensorBoardColabCallback(tbc)])\n","score = model.evaluate(X_test, y_test, batch_size=16)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","Epoch 1/25\n","2444/2444 [==============================] - 247s 101ms/step - loss: 0.6789 - acc: 0.5970\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","Epoch 2/25\n","2444/2444 [==============================] - 246s 101ms/step - loss: 0.6788 - acc: 0.5957\n","Epoch 3/25\n","2444/2444 [==============================] - 248s 102ms/step - loss: 0.6770 - acc: 0.5949\n","Epoch 4/25\n","2444/2444 [==============================] - 248s 101ms/step - loss: 0.6746 - acc: 0.5974\n","Epoch 5/25\n","2444/2444 [==============================] - 246s 101ms/step - loss: 0.6754 - acc: 0.5953\n","Epoch 6/25\n","2444/2444 [==============================] - 246s 101ms/step - loss: 0.6678 - acc: 0.5962\n","Epoch 7/25\n","2444/2444 [==============================] - 246s 101ms/step - loss: 0.6673 - acc: 0.5970\n","Epoch 8/25\n","2444/2444 [==============================] - 245s 100ms/step - loss: 0.6644 - acc: 0.6023\n","Epoch 9/25\n","2444/2444 [==============================] - 246s 101ms/step - loss: 0.6578 - acc: 0.6129\n","Epoch 10/25\n","2444/2444 [==============================] - 246s 101ms/step - loss: 0.6489 - acc: 0.6313\n","Epoch 11/25\n","2444/2444 [==============================] - 246s 101ms/step - loss: 0.6426 - acc: 0.6440\n","Epoch 12/25\n","2444/2444 [==============================] - 246s 101ms/step - loss: 0.6281 - acc: 0.6686\n","Epoch 13/25\n","2444/2444 [==============================] - 245s 100ms/step - loss: 0.6364 - acc: 0.6616\n","Epoch 14/25\n","2444/2444 [==============================] - 246s 100ms/step - loss: 0.6207 - acc: 0.6747\n","Epoch 15/25\n","2444/2444 [==============================] - 247s 101ms/step - loss: 0.6176 - acc: 0.6751\n","Epoch 16/25\n","2444/2444 [==============================] - 246s 100ms/step - loss: 0.6063 - acc: 0.7017\n","Epoch 17/25\n","2444/2444 [==============================] - 246s 101ms/step - loss: 0.5875 - acc: 0.7169\n","Epoch 18/25\n","2444/2444 [==============================] - 245s 100ms/step - loss: 0.5696 - acc: 0.7361\n","Epoch 19/25\n","2444/2444 [==============================] - 246s 100ms/step - loss: 0.5475 - acc: 0.7504\n","Epoch 20/25\n","2444/2444 [==============================] - 245s 100ms/step - loss: 0.5505 - acc: 0.7512\n","Epoch 21/25\n","2444/2444 [==============================] - 244s 100ms/step - loss: 0.5558 - acc: 0.7496\n","Epoch 22/25\n","2444/2444 [==============================] - 245s 100ms/step - loss: 0.5497 - acc: 0.7582\n","Epoch 23/25\n","2444/2444 [==============================] - 244s 100ms/step - loss: 0.5152 - acc: 0.7786\n","Epoch 24/25\n","2444/2444 [==============================] - 245s 100ms/step - loss: 0.4871 - acc: 0.7881\n","Epoch 25/25\n","2444/2444 [==============================] - 245s 100ms/step - loss: 0.4696 - acc: 0.8036\n","612/612 [==============================] - 24s 39ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_kkK5Kv5qBFb","colab_type":"code","outputId":"e3a240b6-3e3f-4328-9bd6-438b4a7d74b6","executionInfo":{"status":"ok","timestamp":1573206984406,"user_tz":-330,"elapsed":958,"user":{"displayName":"AVARI FARZAD","photoUrl":"","userId":"06062050648998271274"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(\"Accuracy: %.2f%%\" % (score[1]*100))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 72.06%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bowEMnNPqBFg","colab_type":"text"},"source":["#### saved model details\n","standardized\n","\n","model = Sequential()\n","#model.add(Embedding(2, output_dim=256))\n","model.add(LSTM(100, input_shape=(time_steps, n_features)))\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, batch_size=16, epochs=50)\n","score = model.evaluate(X_test, y_test, batch_size=16)\n","\n","This model run for 50 epochs had:\n","\n","* binary crossentropy 0.41922928811677918\n","\n","* accuracy 0.8529411764705882"]},{"cell_type":"markdown","metadata":{"id":"UmgCVhtQqBFh","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"rXQrDtI2qBFi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}